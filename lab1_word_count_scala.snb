{"metadata":{"name":"lab1_word_count_scala","user_save_timestamp":"1970-01-01T01:00:00.000Z","auto_save_timestamp":"1970-01-01T01:00:00.000Z","language_info":{"name":"scala","file_extension":"scala","codemirror_mode":"text/x-scala"},"trusted":true,"customLocalRepo":null,"customRepos":null,"customDeps":null,"customImports":null,"customSparkConf":null},"cells":[{"metadata":{},"cell_type":"markdown","source":"# Word Count Lab: Building a word count application with Spark's Scala API\n\nThe volume of unstructured text in existence is growing dramatically, and Spark is an excellent tool for analyzing this type of data. In this lab, we will write code that calculates the most common words in the Complete Works of William Shakespeare retrieved from Project Gutenberg. This could also be scaled to find the most common words on the Internet.\nDuring this lab we will cover: \n- Part 1: Creating a base RDD and pair RDDs\n- Part 2: Counting with pair RDDs\n- Part 3: Finding unique words and a mean value\n- Part 4: Apply word count to a file"},{"metadata":{},"cell_type":"markdown","source":"###Part 1: Creating a base RDD and pair RDDs \nIn this part of the lab, we will explore creating a base RDD with parallelize and using pair RDDs to count words.\n(1a) Create a base RDD \nWe'll start by generating a base RDD by using a Scala list and the sparkContext.parallelize method. Note that the type for the wordsRDD is org.apache.spark.rdd.RDD[String]"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val wordsList = List(\"cat\", \"elephant\", \"rat\", \"rat\", \"cat\")\nval wordsRDD = sparkContext.parallelize(wordsList)","outputs":[{"name":"stdout","output_type":"stream","text":"wordsList: List[String] = List(cat, elephant, rat, rat, cat)\nwordsRDD: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[109] at parallelize at <console>:58\n"},{"metadata":{},"data":{"text/html":"ParallelCollectionRDD[109] at parallelize at &lt;console&gt;:58"},"output_type":"execute_result","execution_count":98}]},{"metadata":{},"cell_type":"markdown","source":"This is an example of a simple function to pluralize a word i.e. it adds an \"s\" to the string"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"def makePlural(word: String) = word + \"s\"","outputs":[{"name":"stdout","output_type":"stream","text":"makePlural: (word: String)String\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":6}]},{"metadata":{},"cell_type":"markdown","source":"Use the function 'makePlural' to pluralize the wordsRDD with 'map' then use 'foreach(println)' to display the result"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"wordsRDD.map(x => makePlural(x)).foreach(println)","outputs":[{"name":"stdout","output_type":"stream","text":"cats\nrats\nelephants\nrats\ncats\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":101}]},{"metadata":{},"cell_type":"markdown","source":"These actions can be broken down to make it clearer"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val pluralRDD = wordsRDD.map(x => makePlural(x)) // map each word to the makePlural function\npluralRDD.take(3).foreach(println) // take three elements and print each of them","outputs":[{"name":"stdout","output_type":"stream","text":"cats\nelephants\nrats\npluralRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[111] at map at <console>:67\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":102}]},{"metadata":{},"cell_type":"markdown","source":"For such small functions it's cleaner to use an anonymous function"},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"// Use anonymous function to pluralize\nval pluralRDD = wordsRDD.map(x => x + \"s\") // add an \"s\" to each element in wordsRDD\npluralRDD.take(3).foreach(println)","outputs":[{"name":"stdout","output_type":"stream","text":"cats\nelephants\nrats\npluralRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[113] at map at <console>:62\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":104}]},{"metadata":{},"cell_type":"markdown","source":"Use map( ) and an anonymous function to return the number of characters in each word. We'll collect this result directly into a variable using collect. Note you can call collect with or without the ( ) at the end."},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"// Length of each word in the list\nval pluralLengths = pluralRDD.map(x => x.length).collect","outputs":[{"name":"stdout","output_type":"stream","text":"pluralLengths: Array[Int] = Array(4, 9, 4, 4, 4)\n"},{"metadata":{},"data":{"text/html":"<div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon561ad75ce1724cd6fa06d5d911c11424&quot;,&quot;dataInit&quot;:[{&quot;X&quot;:0,&quot;Y&quot;:4},{&quot;X&quot;:1,&quot;Y&quot;:9},{&quot;X&quot;:2,&quot;Y&quot;:4},{&quot;X&quot;:3,&quot;Y&quot;:4},{&quot;X&quot;:4,&quot;Y&quot;:4}],&quot;genId&quot;:&quot;495168385&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tabs'], \n      function(playground, _magictabs) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictabs,\n    \"o\": {}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n        <ul class=\"nav nav-tabs\" id=\"ul495168385\"><li>\n              <a href=\"#tab495168385-0\"><i class=\"fa fa-table\"/></a>\n            </li><li>\n              <a href=\"#tab495168385-1\"><i class=\"fa fa-dot-circle-o\"/></a>\n            </li><li>\n              <a href=\"#tab495168385-2\"><i class=\"fa fa-line-chart\"/></a>\n            </li><li>\n              <a href=\"#tab495168385-3\"><i class=\"fa fa-bar-chart\"/></a>\n            </li></ul>\n\n        <div class=\"tab-content\" id=\"tab495168385\"><div class=\"tab-pane\" id=\"tab495168385-0\">\n            <div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon8b08f1b2a5f016ff615ee8dd9c5c3bba&quot;,&quot;dataInit&quot;:[{&quot;X&quot;:0,&quot;Y&quot;:4},{&quot;X&quot;:1,&quot;Y&quot;:9},{&quot;X&quot;:2,&quot;Y&quot;:4},{&quot;X&quot;:3,&quot;Y&quot;:4},{&quot;X&quot;:4,&quot;Y&quot;:4}],&quot;genId&quot;:&quot;688991930&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tableChart'], \n      function(playground, _magictableChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictableChart,\n    \"o\": {\"headers\":[\"X\",\"Y\"],\"nrow\":5,\"shown\":5,\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    </div>\n            </div><div class=\"tab-pane\" id=\"tab495168385-1\">\n            <div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon437eb67618f92434508d36685a5fae1a&quot;,&quot;dataInit&quot;:[{&quot;X&quot;:0,&quot;Y&quot;:4},{&quot;X&quot;:1,&quot;Y&quot;:9},{&quot;X&quot;:2,&quot;Y&quot;:4},{&quot;X&quot;:3,&quot;Y&quot;:4},{&quot;X&quot;:4,&quot;Y&quot;:4}],&quot;genId&quot;:&quot;488781528&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/scatterChart'], \n      function(playground, _magicscatterChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magicscatterChart,\n    \"o\": {\"x\":\"X\",\"y\":\"Y\",\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    </div>\n            </div><div class=\"tab-pane\" id=\"tab495168385-2\">\n            <div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anonc1e8ee4ef7d52ff8875036c5d9c5f865&quot;,&quot;dataInit&quot;:[{&quot;X&quot;:0,&quot;Y&quot;:4},{&quot;X&quot;:1,&quot;Y&quot;:9},{&quot;X&quot;:2,&quot;Y&quot;:4},{&quot;X&quot;:3,&quot;Y&quot;:4},{&quot;X&quot;:4,&quot;Y&quot;:4}],&quot;genId&quot;:&quot;1460137467&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/lineChart'], \n      function(playground, _magiclineChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magiclineChart,\n    \"o\": {\"x\":\"X\",\"y\":\"Y\",\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    </div>\n            </div><div class=\"tab-pane\" id=\"tab495168385-3\">\n            <div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon1bf9c11bb45953bf1ba78dbfb8d44421&quot;,&quot;dataInit&quot;:[{&quot;X&quot;:0,&quot;Y&quot;:4},{&quot;X&quot;:1,&quot;Y&quot;:9},{&quot;X&quot;:2,&quot;Y&quot;:4},{&quot;X&quot;:3,&quot;Y&quot;:4},{&quot;X&quot;:4,&quot;Y&quot;:4}],&quot;genId&quot;:&quot;1056999881&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/barChart'], \n      function(playground, _magicbarChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magicbarChart,\n    \"o\": {\"x\":\"X\",\"y\":\"Y\",\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    </div>\n            </div></div>\n      </div></div>"},"output_type":"execute_result","execution_count":105}]},{"metadata":{},"cell_type":"markdown","source":"###Pair RDDs \nThe next step in writing our word counting program is to create a new type of RDD, called a pair RDD. A pair RDD is an RDD where each element is a pair tuple (k, v) where k is the key and v is the value. In this example, we will create a pair consisting of ('<word>', 1) for each word element in the RDD.\nWe can create the pair RDD using the map(  ) transformation with an anonymous function to create a new RDD."},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val wordPairs = wordsRDD.map(x => (x ,1))\nwordPairs.collect().foreach(println)","outputs":[{"name":"stdout","output_type":"stream","text":"(cat,1)\n(elephant,1)\n(rat,1)\n(rat,1)\n(cat,1)\nwordPairs: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[13] at map at <console>:47\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":28}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"// counting with the word pairs\nval wordCounts = wordPairs.reduceByKey(_+_)\nwordCounts.foreach(println)","outputs":[{"name":"stdout","output_type":"stream","text":"(cat,2)\n(rat,2)\n(elephant,1)\nwordCounts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[15] at reduceByKey at <console>:49\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":30}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"// Expert version all commands in one go\nval wordCounts = wordsRDD.map(x => (x, 1)).reduceByKey(_+_)\nwordCounts.collect().foreach(println)","outputs":[{"name":"stdout","output_type":"stream","text":"(rat,2)\n(elephant,1)\n(cat,2)\nwordCounts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[19] at reduceByKey at <console>:47\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":32}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"// Get the number of unique words\nval uniqueCount = wordCounts.map(x => 1).reduce(_+_)\nprintln(uniqueCount)","outputs":[{"name":"stdout","output_type":"stream","text":"3\nuniqueCount: Int = 3\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":33}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"// Total count of words & average\nval totalCount = wordCounts.map(x => x._2).reduce(_+_)\nprintln(totalCount)\nval average = totalCount.toFloat / uniqueCount\nprintln(average)","outputs":[{"name":"stdout","output_type":"stream","text":"5\n1.6666666\ntotalCount: Int = 5\naverage: Float = 1.6666666\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":39}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"// function that creates a pair RDD with word counts from an RDD of words\n// TODO: got to be a better way of refering to org.apache.spark.rdd.RDD[String]\ndef wordCount(wordListRDD: org.apache.spark.rdd.RDD[String]) = wordListRDD.map(x => (x, 1)).reduceByKey(_+_)","outputs":[{"name":"stdout","output_type":"stream","text":"wordCount: (wordListRDD: org.apache.spark.rdd.RDD[String])org.apache.spark.rdd.RDD[(String, Int)]\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":43}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"wordCount(wordsRDD).collect().foreach(println)","outputs":[{"name":"stdout","output_type":"stream","text":"(rat,2)\n(elephant,1)\n(cat,2)\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":45}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"//import scala.util.matching.Regex\ndef removePunctuation(text: String) = {\n  text.toLowerCase()\n  .replaceAll(\"[^A-Za-z0-9 ]\",\"\")\n  .trim()\n}\nprintln(removePunctuation(\"   This is My Test String!    \"))","outputs":[{"name":"stdout","output_type":"stream","text":"this is my test string\nremovePunctuation: (text: String)String\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":60}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"// test remove punctuation\nprintln(removePunctuation(\"Hi, you!\"))\nprintln(removePunctuation(\" No under_score!\"))\nprintln(removePunctuation(\" *      Remove punctuation then spaces  * \"))","outputs":[{"name":"stdout","output_type":"stream","text":"hi you\nno underscore\nremove punctuation then spaces\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":62}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"// change the dataFile value here to where you downloaded shakespeare.txt to\nval dataFile = \"/Users/Izham/data/shakespeare.txt\"\nval shakespeareRDD = sparkContext.textFile(dataFile).map(removePunctuation)","outputs":[{"name":"stdout","output_type":"stream","text":"dataFile: String = /Users/Izham/data/shakespeare.txt\nshakespeareRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[40] at map at <console>:61\n"},{"metadata":{},"data":{"text/html":"MapPartitionsRDD[40] at map at &lt;console&gt;:61"},"output_type":"execute_result","execution_count":73}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"// have a peek at the first five lines of the loaded file\nshakespeareRDD.take(15)","outputs":[{"name":"stdout","output_type":"stream","text":"res44: Array[String] = Array(1609, \"\", the sonnets, \"\", by william shakespeare, \"\", \"\", \"\", 1, from fairest creatures we desire increase, that thereby beautys rose might never die, but as the riper should by time decease, his tender heir might bear his memory, but thou contracted to thine own bright eyes, feedst thy lights flame with selfsubstantial fuel)\n"},{"metadata":{},"data":{"text/html":"<div class=\"container-fluid\"><div><div class=\"col-md-12\"><div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon3ff3d19568af679ac288832160989efc&quot;,&quot;dataInit&quot;:[{&quot;string value&quot;:&quot;1609&quot;},{&quot;string value&quot;:&quot;&quot;},{&quot;string value&quot;:&quot;the sonnets&quot;},{&quot;string value&quot;:&quot;&quot;},{&quot;string value&quot;:&quot;by william shakespeare&quot;},{&quot;string value&quot;:&quot;&quot;},{&quot;string value&quot;:&quot;&quot;},{&quot;string value&quot;:&quot;&quot;},{&quot;string value&quot;:&quot;1&quot;},{&quot;string value&quot;:&quot;from fairest creatures we desire increase&quot;},{&quot;string value&quot;:&quot;that thereby beautys rose might never die&quot;},{&quot;string value&quot;:&quot;but as the riper should by time decease&quot;},{&quot;string value&quot;:&quot;his tender heir might bear his memory&quot;},{&quot;string value&quot;:&quot;but thou contracted to thine own bright eyes&quot;},{&quot;string value&quot;:&quot;feedst thy lights flame with selfsubstantial fuel&quot;}],&quot;genId&quot;:&quot;659078673&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tableChart'], \n      function(playground, _magictableChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictableChart,\n    \"o\": {\"headers\":[\"string value\"],\"nrow\":15,\"shown\":15,\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    </div></div></div></div>"},"output_type":"execute_result","execution_count":77}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val shakespeareWordsRDD = shakespeareRDD.flatMap(line => line.split(' '))\nval shakespeareWordCount = shakespeareWordsRDD.count()\nshakespeareWordsRDD.top(5).foreach(println)","outputs":[{"name":"stdout","output_type":"stream","text":"zwaggerd\nzounds\nzounds\nzounds\nzounds\nshakespeareWordsRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[43] at flatMap at <console>:63\nshakespeareWordCount: Long = 927631\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":81}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"// wrong way with map\nval wrongWordsRDD = shakespeareRDD.map(line => line.split(' '))\nval wrongWordCount = shakespeareWordsRDD.count()\nwrongWordsRDD.take(5).foreach(println)","outputs":[{"name":"stdout","output_type":"stream","text":"[Ljava.lang.String;@1fc7eaeb\n[Ljava.lang.String;@1449b52e\n[Ljava.lang.String;@38cfeb7a\n[Ljava.lang.String;@2c3b96e8\n[Ljava.lang.String;@c0ba136\nwrongWordsRDD: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[45] at map at <console>:66\nwrongWordCount: Long = 927631\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":83}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"// remove empty elements where words are ''\nval shakeWordsRDD = shakespeareWordsRDD.filter(x => x != \"\")\nval shakeWordCount = shakeWordsRDD.count","outputs":[{"name":"stdout","output_type":"stream","text":"shakeWordsRDD: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[46] at filter at <console>:64\nshakeWordCount: Long = 882996\n"},{"metadata":{},"data":{"text/html":"882996"},"output_type":"execute_result","execution_count":84}]},{"metadata":{"trusted":true,"input_collapsed":false,"collapsed":false},"cell_type":"code","source":"val top15WordsAndCounts = wordCount(shakeWordsRDD).sortBy(x => x._2, false)\ntop15WordsAndCounts.take(15).foreach(println)","outputs":[{"name":"stdout","output_type":"stream","text":"(the,27361)\n(and,26028)\n(i,20681)\n(to,19150)\n(of,17463)\n(a,14593)\n(you,13615)\n(my,12481)\n(in,10956)\n(that,10890)\n(is,9134)\n(not,8497)\n(with,7771)\n(me,7769)\n(it,7678)\ntop15WordsAndCounts: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[108] at sortBy at <console>:69\n"},{"metadata":{},"data":{"text/html":""},"output_type":"execute_result","execution_count":95}]}],"nbformat":4}